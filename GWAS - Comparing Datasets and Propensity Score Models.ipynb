{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import exp, log\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy as sp\n",
    "from scipy import stats\n",
    "from scipy.special import expit\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor\n",
    "from sklearn.linear_model import LogisticRegression,  LogisticRegressionCV, LinearRegression, Ridge, ElasticNet\n",
    "from sklearn.decomposition import PCA, FactorAnalysis\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "from sklearn.calibration import calibration_curve, CalibrationDisplay\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import LearningCurveDisplay, ShuffleSplit, learning_curve, validation_curve\n",
    "from sklearn.model_selection import train_test_split\n",
    "from numpy import linalg as LA\n",
    "\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "import matplotlib.pyplot as plt\n",
    "import limix\n",
    "import pdb\n",
    "\n",
    "from numpy import array\n",
    "from numpy_sugar.linalg import economic_qs_linear\n",
    "from glimix_core.lmm import LMM\n",
    "\n",
    "\n",
    "%matplotlib inline \n",
    "\n",
    "import seaborn as sns\n",
    "sns.set_style(\"whitegrid\")\n",
    "sns.set_context(\"notebook\", font_scale=1.5, rc={\"lines.linewidth\": 2.5})\n",
    "plt.rcParams['figure.figsize'] = 10, 8\n",
    "\n",
    "np.seterr(divide='ignore', invalid='ignore')\n",
    "np.random.seed(42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ece(y_true, y_pred, n_bins=10, title='text'):\n",
    "    x_axis = np.arange(0, 1.1, (1.0)/n_bins)\n",
    "    y_axis = np.zeros(x_axis.shape)\n",
    "    x_axis_new = np.zeros(x_axis.shape)\n",
    "    bin_count = np.zeros(x_axis.shape)\n",
    "    zero_indices = []\n",
    "    N = len(y_true)\n",
    "    score = 0\n",
    "    for i, x in enumerate(x_axis):\n",
    "        if(i==0):\n",
    "            continue\n",
    "        bin_outputs = y_true[np.logical_and(y_pred<=x, y_pred>x_axis[i-1])]\n",
    "        bin_preds = y_pred[np.logical_and(y_pred<=x, y_pred>x_axis[i-1])]\n",
    "        \n",
    "            \n",
    "        if(len(bin_outputs)>0):\n",
    "            y_axis[i]=bin_outputs.mean()\n",
    "            avg_pred = bin_preds.mean()\n",
    "            x_axis_new[i] = avg_pred\n",
    "        else:\n",
    "            y_axis[i]=0\n",
    "            avg_pred = 0\n",
    "            x_axis_new[i] = x\n",
    "            zero_indices += [i] \n",
    "        \n",
    "        \n",
    "        bin_count[i] = len(bin_outputs)\n",
    "        score+=abs(y_axis[i]-avg_pred)*((1.0*len(bin_outputs))/N)\n",
    "    return score  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_baselines=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working with Dataset 0\n",
      "Reading SNP 0\n",
      "Reading SNP 1\n",
      "Reading SNP 2\n",
      "Reading SNP 3\n",
      "Reading SNP 4\n",
      "Reading SNP 5\n",
      "Reading SNP 6\n",
      "Reading SNP 7\n",
      "Reading SNP 8\n",
      "Reading SNP 9\n",
      "Reading SNP 10\n",
      "Reading SNP 11\n",
      "Reading SNP 12\n",
      "Reading SNP 13\n",
      "Reading SNP 14\n",
      "Reading SNP 15\n",
      "Reading SNP 16\n",
      "Reading SNP 17\n",
      "Reading SNP 18\n",
      "Reading SNP 19\n",
      "Reading SNP 20\n",
      "Reading SNP 21\n",
      "Reading SNP 22\n",
      "Reading SNP 23\n",
      "Reading SNP 24\n",
      "Reading SNP 25\n",
      "Reading SNP 26\n",
      "Reading SNP 27\n",
      "Reading SNP 28\n",
      "Reading SNP 29\n",
      "Reading SNP 30\n",
      "Reading SNP 31\n",
      "Reading SNP 32\n",
      "Reading SNP 33\n",
      "Reading SNP 34\n",
      "Reading SNP 35\n",
      "Reading SNP 36\n",
      "Reading SNP 37\n",
      "Reading SNP 38\n",
      "Reading SNP 39\n",
      "Reading SNP 40\n",
      "Reading SNP 41\n",
      "Reading SNP 42\n",
      "Reading SNP 43\n",
      "Reading SNP 44\n",
      "Reading SNP 45\n",
      "Reading SNP 46\n",
      "Reading SNP 47\n",
      "Reading SNP 48\n",
      "Reading SNP 49\n",
      "Reading SNP 50\n",
      "Reading SNP 51\n",
      "Reading SNP 52\n",
      "Reading SNP 53\n",
      "Reading SNP 54\n",
      "Reading SNP 55\n",
      "Reading SNP 56\n",
      "Reading SNP 57\n",
      "Reading SNP 58\n",
      "Reading SNP 59\n",
      "Reading SNP 60\n",
      "Reading SNP 61\n",
      "Reading SNP 62\n",
      "Reading SNP 63\n",
      "Reading SNP 64\n",
      "Reading SNP 65\n",
      "Reading SNP 66\n",
      "Reading SNP 67\n",
      "Reading SNP 68\n",
      "Reading SNP 69\n",
      "Reading SNP 70\n",
      "Reading SNP 71\n",
      "Reading SNP 72\n",
      "Reading SNP 73\n",
      "Reading SNP 74\n",
      "Reading SNP 75\n",
      "Reading SNP 76\n",
      "Reading SNP 77\n",
      "Reading SNP 78\n",
      "Reading SNP 79\n",
      "Reading SNP 80\n",
      "Reading SNP 81\n",
      "Reading SNP 82\n",
      "Reading SNP 83\n",
      "Reading SNP 84\n",
      "Reading SNP 85\n",
      "Reading SNP 86\n",
      "Reading SNP 87\n",
      "Reading SNP 88\n",
      "Reading SNP 89\n",
      "Reading SNP 90\n",
      "Reading SNP 91\n",
      "Reading SNP 92\n",
      "Reading SNP 93\n",
      "Reading SNP 94\n",
      "Reading SNP 95\n",
      "Reading SNP 96\n",
      "Reading SNP 97\n",
      "Reading SNP 98\n",
      "Reading SNP 99\n",
      "printing result\n",
      "tensor([[   33.49476,    78.84949,    22.72853,    23.90821,    13.22333,\n",
      "            11.71626,    11.47016,    24.01028,     0.04088,     0.00213,\n",
      "             0.00000,     0.00000]])\n",
      "tensor([   33.49476,    78.84949,    22.72853,    23.90821,    13.22333,\n",
      "           11.71626,    11.47016,    24.01028,     0.04088,     0.00213,\n",
      "            0.00000,     0.00000])\n",
      "tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan])\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "from sklearn.gaussian_process.kernels import RBF\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "names = [\n",
    "    \"Neural Net\",\n",
    "    \"Decision Tree\",\n",
    "    \"Random Forest\",\n",
    "    \"AdaBoost\",\n",
    "    \"Naive Bayes\",\n",
    "]\n",
    "\n",
    "classifiers = [\n",
    "    MLPClassifier(alpha=1, max_iter=10000, early_stopping=True),\n",
    "    DecisionTreeClassifier(max_depth=5),\n",
    "    RandomForestClassifier(max_depth=5, n_estimators=10),\n",
    "    AdaBoostClassifier(),\n",
    "    GaussianNB(),\n",
    "]\n",
    "datasets = [\n",
    "    'bn_sim100_',\n",
    "    'sp0_3_sim100_',\n",
    "    'sp0_5_sim100_',\n",
    "    'tgp_sim100_',\n",
    "    'hgdp_sim100_',\n",
    "]\n",
    "\n",
    "\n",
    "EXP_REPS = 10\n",
    "NUM_SNPS = 100\n",
    "epsilon = 1e-2\n",
    "\n",
    "\n",
    "# Results\n",
    "naive_est_marginal_betas = torch.zeros((EXP_REPS, NUM_SNPS))\n",
    "plain_iptw_est_marginal_betas = torch.zeros((EXP_REPS, NUM_SNPS))\n",
    "calib_iptw_est_marginal_betas = torch.zeros((EXP_REPS, NUM_SNPS))\n",
    "plain_aipw_est_marginal_betas = torch.zeros((EXP_REPS, NUM_SNPS))\n",
    "calib_aipw_est_marginal_betas = torch.zeros((EXP_REPS, NUM_SNPS))\n",
    "\n",
    "beta_pca = torch.zeros((EXP_REPS, NUM_SNPS))\n",
    "beta_fa = torch.zeros((EXP_REPS, NUM_SNPS))\n",
    "beta_lmm = torch.zeros((EXP_REPS, NUM_SNPS))\n",
    "beta_true = np.zeros((EXP_REPS, NUM_SNPS))\n",
    "cal_scores = torch.zeros((EXP_REPS, NUM_SNPS, 2))\n",
    "cal_scores_train = torch.zeros((EXP_REPS, NUM_SNPS, 2))\n",
    "\n",
    "\n",
    "for CLASSIFIER_ID, classifier in enumerate(classifiers):\n",
    "    for dataset in datasets:\n",
    "        for dataset_idx in range(0,EXP_REPS):\n",
    "            print(\"Working with Dataset \"+str(dataset_idx))\n",
    "            \n",
    "            simulated_data = torch.load('simulated_gwas/'+dataset+str(dataset_idx)+'.pt')\n",
    "\n",
    "            N = simulated_data['snps'].shape[1]\n",
    "            \n",
    "            M = simulated_data['snps'].shape[0]\n",
    "            G = simulated_data['snps'][:int(0.8*M)]\n",
    "            Y = simulated_data['outcomes'][:int(0.8*M)]\n",
    "            Z = simulated_data['clusters'][:int(0.8*M)]\n",
    "\n",
    "            G_test = simulated_data['snps'][int(0.8*M):]\n",
    "            Y_test = simulated_data['outcomes'][int(0.8*M):]\n",
    "            Z_test = simulated_data['clusters'][int(0.8*M):]\n",
    "            beta_true[dataset_idx] = betas = simulated_data['true_betas']\n",
    "\n",
    "\n",
    "\n",
    "            # iterate through snp vector sequentially\n",
    "\n",
    "\n",
    "\n",
    "            for snp_index in range((G.shape[1])):\n",
    "\n",
    "\n",
    "                print(\"Reading SNP \"+str(snp_index))\n",
    "\n",
    "\n",
    "                T = G[:, snp_index]\n",
    "                T_test = G_test[:, snp_index]\n",
    "\n",
    "                X = np.concatenate((G[:, :snp_index], G[:, snp_index+1:]), axis=1)\n",
    "\n",
    "                X_test = np.concatenate((G_test[:, :snp_index], G_test[:, snp_index+1:]), axis=1)\n",
    "\n",
    "       \n",
    "                if(run_baselines):\n",
    "                    pc = PCA(n_components=10)\n",
    "                    pc_snps = StandardScaler().fit_transform(pc.fit_transform(X))\n",
    "\n",
    "                    G_pca = np.concatenate((T.reshape(-1,1), pc_snps), axis=1)\n",
    "                    beta_pca[dataset_idx][snp_index] = (Ridge().fit(G_pca, Y).coef_)[0]\n",
    "\n",
    "                    pc_snps_test = StandardScaler().fit_transform(pc.transform(X_test))\n",
    "                    G_pca = np.concatenate((T_test.reshape(-1,1), pc_snps_test), axis=1)\n",
    "                    \n",
    "\n",
    "                    QS = economic_qs_linear(X)\n",
    "                    covariates = X\n",
    "                    y = Y\n",
    "                    lmm = LMM(y, T, QS)\n",
    "                    lmm.fit(verbose=False)\n",
    "                    beta_lmm[dataset_idx][snp_index] = lmm.beta[0]\n",
    "\n",
    "                    fa = FactorAnalysis(n_components=10)\n",
    "                    fa_snps = fa.fit_transform(X)\n",
    "                    fa_snps = StandardScaler().fit_transform(fa_snps)\n",
    "                    G_fa = np.concatenate((T.reshape(-1,1), fa_snps), axis=1)\n",
    "                    beta_fa[dataset_idx][snp_index] = (Ridge().fit(G_fa, Y).coef_)[0]\n",
    "\n",
    "                    fa_snps_test = StandardScaler().fit_transform(fa.transform(X_test))\n",
    "                    G_fa = np.concatenate((T_test.reshape(-1,1), fa_snps_test), axis=1)\n",
    "                    \n",
    "\n",
    "                reg1 = Ridge().fit(X[T==1], Y[T==1])\n",
    "                reg0 = Ridge().fit(X[T==0], Y[T==0])\n",
    "\n",
    "\n",
    "                naive_est_marginal_betas[dataset_idx][snp_index] = (reg1.predict(X) - reg0.predict(X)).mean() # assuming linear model\n",
    "  \n",
    "                prop_model = classifiers[CLASSIFIER_ID].fit(X, T)\n",
    "\n",
    "\n",
    "                prop_scores = np.clip(prop_model.predict_proba(X)[:, 1], a_min = epsilon, a_max = 1-epsilon) # clipping necessary before inverting\n",
    "                prop_scores_test = np.clip(prop_model.predict_proba(X_test)[:, 1], a_min = epsilon, a_max = 1-epsilon)\n",
    "\n",
    "\n",
    "\n",
    "                cal_scores[dataset_idx][snp_index][0] = ece(T_test, prop_model.predict_proba(X_test)[:, 1], title='Before calibration [Test]')\n",
    "                cal_scores_train[dataset_idx][snp_index][0] = ece(T, prop_model.predict_proba(X)[:, 1], title='Before calibration [Train]')\n",
    "\n",
    "\n",
    "                plain_iptw_est_marginal_betas[dataset_idx][snp_index] = ((T/prop_scores)*Y - ((1-T)/(1-prop_scores))*Y).mean()\n",
    "\n",
    "\n",
    "                plain_aipw_est_marginal_betas[dataset_idx][snp_index] = plain_iptw_est_marginal_betas[dataset_idx][snp_index] + ((prop_scores - T)*reg0.predict(X)/(1 - prop_scores) + (prop_scores - T)*reg1.predict(X)/(prop_scores)).mean()\n",
    "\n",
    "                prop_model_calib = CalibratedClassifierCV(prop_model, method='isotonic', ensemble=True, cv='prefit') # works\n",
    "                prop_model_calib.fit(X, T)\n",
    "\n",
    "\n",
    "                prop_scores = np.clip(prop_model_calib.predict_proba(X)[:, 1], a_min = epsilon, a_max = 1-epsilon)\n",
    "\n",
    "                prop_scores_test = np.clip(prop_model_calib.predict_proba(X_test)[:, 1], a_min = epsilon, a_max = 1-epsilon)\n",
    "\n",
    "                cal_scores[dataset_idx][snp_index][1] = ece(T_test, prop_model_calib.predict_proba(X_test)[:, 1], title='After calibration [Test]')\n",
    "                cal_scores_train[dataset_idx][snp_index][1] = ece(T, prop_model_calib.predict_proba(X)[:, 1], title='After calibration [Train]')\n",
    "                \n",
    "                calib_iptw_est_marginal_betas[dataset_idx][snp_index] = ((T/prop_scores)*Y - ((1-T)/(1-prop_scores))*Y).mean()\n",
    "\n",
    "\n",
    "                calib_aipw_est_marginal_betas[dataset_idx][snp_index] = calib_iptw_est_marginal_betas[dataset_idx][snp_index] + ((prop_scores - T)*reg0.predict(X)/(1 - prop_scores) + (prop_scores - T)*reg1.predict(X)/(prop_scores)).mean()\n",
    "\n",
    "\n",
    "\n",
    "        EXP_REPS = len(calib_iptw_est_marginal_betas)\n",
    "        result_norms = torch.zeros(EXP_REPS, 12)\n",
    "        for i in range(EXP_REPS):\n",
    "\n",
    "            result_norms[i][0] = (LA.norm(calib_iptw_est_marginal_betas[i] - beta_true[i]))\n",
    "            result_norms[i][1] = (LA.norm(plain_iptw_est_marginal_betas[i] - beta_true[i]))\n",
    "            result_norms[i][2] = (LA.norm(calib_aipw_est_marginal_betas[i] - beta_true[i]))\n",
    "            result_norms[i][3] = (LA.norm(plain_aipw_est_marginal_betas[i] - beta_true[i]))\n",
    "\n",
    "            result_norms[i][4] = (LA.norm(beta_pca[i] - beta_true[i]))\n",
    "            result_norms[i][5] = (LA.norm(beta_fa[i] - beta_true[i]))\n",
    "            result_norms[i][6] = (LA.norm(beta_lmm[i] - beta_true[i]))\n",
    "            result_norms[i][7] = (LA.norm(naive_est_marginal_betas[i] - beta_true[i]))\n",
    "            result_norms[i][8] = (cal_scores_train[i][:, 0]).mean(axis=0)\n",
    "            result_norms[i][9] = (cal_scores_train[i][:, 0]).std(axis=0)/np.sqrt(len(cal_scores[i]))\n",
    "            result_norms[i][10] = (cal_scores_train[i][:, 1]).mean(axis=0)\n",
    "            result_norms[i][11] = (cal_scores_train[i][:, 1]).std(axis=0)/np.sqrt(len(cal_scores[i]))\n",
    "        torch.set_printoptions(precision=5, sci_mode=False)\n",
    "        print(\"printing result\")\n",
    "        print(result_norms)\n",
    "        print(result_norms.mean(axis=0))\n",
    "        print(result_norms.std(axis=0)/np.sqrt(len(result_norms)))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
